# kaz_legal_web_api.py (–í–µ—Ä—Å–∏—è 3.0 - –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω–∞—è –∏ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π —Å—Ç—Ä–∏–º–∏–Ω–≥–∞)
from flask import Flask, request, jsonify, Response, stream_with_context, send_from_directory
import google.generativeai as genai
import os
import json
import re
from flask_cors import CORS

app = Flask(__name__, static_folder='../frontend', static_url_path='')
CORS(app, origins=["https://ai-lawyer-tau.vercel.app"])

# üß† –ù–∞—Å—Ç—Ä–æ–π–∫–∞ Gemini API
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY", "")
genai.configure(api_key=GEMINI_API_KEY)
# --- –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –í–∫–ª—é—á–∞–µ–º stream=True –¥–ª—è –ø–æ—Ç–æ–∫–æ–≤–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ ---
model = genai.GenerativeModel('gemini-1.5-flash')

# –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ—Å—Ç—É—é –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö, –∫–∞–∫ –≤ –æ—Ä–∏–≥–∏–Ω–∞–ª–µ, –±–µ–∑ –Ω–µ—Ä–∞–±–æ—Ç–∞—é—â–µ–π –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏
LAW_DB = [] 

# üß† –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π —Å–ª–æ–≤–∞—Ä—å —Å–∏–Ω–æ–Ω–∏–º–æ–≤ (–Ω–µ–º–Ω–æ–≥–æ –¥–æ–ø–æ–ª–Ω–µ–Ω)
LEGAL_SYNONYMS = {
    '—É–≤–æ–ª—å–Ω–µ–Ω–∏–µ': ['—É–≤–æ–ª—å–Ω', '—Ä–∞—Å—Ç–æ—Ä–∂', '–ø—Ä–µ–∫—Ä–∞—â', '–æ—Å–≤–æ–±–æ–∂–¥', '—É–≤–æ–ª—å', '—Ä–∞—Å—Ç–æ—Ä–≥–Ω', '–ø—Ä–µ–∫—Ä–∞—Ç', '–¥–∏—Å—Ü–∏–ø–ª–∏–Ω–∞—Ä', '—Å–æ–∫—Ä–∞—â'],
    '–∑–∞—Ä–ø–ª–∞—Ç–∞': ['–∑–∞—Ä–∞–±–æ—Ç–Ω', '–æ–ø–ª–∞—Ç', '–≤—ã–ø–ª–∞—Ç', '–≤–æ–∑–Ω–∞–≥—Ä–∞–∂', '–∂–∞–ª–æ–≤–∞–Ω', '–¥–æ—Ö–æ–¥', '–ø—Ä–µ–º–∏–∞–ª—å–Ω', '–Ω–∞–¥–±–∞–≤–∫', '–∑–∞—Ä–ø–ª–∞—Ç'],
    '—Ä–∞–±–æ—Ç–∞': ['—Ç—Ä—É–¥', '—Ä–∞–±–æ—Ç', '—Å–ª—É–∂–±', '–¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç', '–∑–∞–Ω—è—Ç–æ—Å—Ç', '–ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω', '–¥–æ–ª–∂–Ω–æ—Å—Ç'],
    '—Ä–∞–±–æ—Ç–Ω–∏–∫': ['—Å–æ—Ç—Ä—É–¥–Ω–∏–∫', '—Å–ª—É–∂–∞—â', '–ø–µ—Ä—Å–æ–Ω–∞–ª', '–∫–∞–¥—Ä', '—Ä–∞–±–æ—Ç—è–≥', '—Ç—Ä—É–¥—è—â'],
    '—Ä–∞–±–æ—Ç–æ–¥–∞—Ç–µ–ª—å': ['–Ω–∞–Ω–∏–º–∞—Ç–µ–ª—å', '–ø—Ä–µ–¥–ø—Ä–∏—è—Ç–∏–µ', '–æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏', '–∫–æ–º–ø–∞–Ω–∏', '—É—á—Ä–µ–∂–¥–µ–Ω', '—Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª'],
    '–¥–æ–≥–æ–≤–æ—Ä': ['—Å–æ–≥–ª–∞—à–µ–Ω', '–∫–æ–Ω—Ç—Ä–∞–∫—Ç', '—Å–¥–µ–ª–∫', '–æ–±—è–∑–∞—Ç–µ–ª—å—Å—Ç–≤', '—É—Å–ª–æ–≤–∏–µ'],
    # --- –£–õ–£–ß–®–ï–ù–ò–ï: –î–æ–±–∞–≤–ª–µ–Ω—ã –Ω–æ–≤—ã–µ —Å–∏–Ω–æ–Ω–∏–º—ã –¥–ª—è –≤–∞—à–µ–≥–æ –∑–∞–ø—Ä–æ—Å–∞ ---
    '—É—á–∏—Ç–µ–ª—å': ['—É—á–∏—Ç–µ–ª', '–ø—Ä–µ–ø–æ–¥–∞–≤–∞—Ç–µ–ª', '–ø–µ–¥–∞–≥–æ–≥', '–Ω–∞—Å—Ç–∞–≤–Ω–∏–∫'],
    '—É—á–µ–Ω–∏–∫': ['—É—á–∞—â', '—à–∫–æ–ª—å–Ω', '—Å—Ç—É–¥–µ–Ω—Ç', '–≤–æ—Å–ø–∏—Ç–∞–Ω'],
    '–Ω–∞—Å–∏–ª–∏–µ': ['–Ω–∞—Å–∏–ª–∏', '–∂–µ—Å—Ç–æ–∫', '–ø—Ä–∏–Ω—É–∂–¥–µ–Ω', '–∞–≥—Ä–µ—Å—Å–∏', '–∏–∑–±–∏–µ–Ω', '–¥–æ–º–∞—à–Ω', '–Ω–∞—Å–∏–ª—å—Å—Ç–≤–µ–Ω', '—É–¥–∞—Ä', '–ø–æ–±–æ', '–±—å–µ—Ç'],
    '—Ä–µ–±–µ–Ω–æ–∫': ['—Ä–µ–±–µ–Ω', '–Ω–µ—Å–æ–≤–µ—Ä—à–µ–Ω–Ω–æ–ª–µ—Ç', '–º–∞–ª–æ–ª–µ—Ç', '–¥–∏—Ç—è', '–ø–æ–¥—Ä–æ—Å—Ç'],
    '–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ': ['–æ–±—Ä–∞–∑–æ–≤–∞–Ω', '–æ–±—É—á–µ–Ω', '—à–∫–æ–ª', '—É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç', '–∫–æ–ª–ª–µ–¥–∂', '–ª–∏—Ü–µ–π', '–≥–∏–º–Ω–∞–∑']
}

# --- –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –í–æ–∑–≤—Ä–∞—â–∞–µ–º—Å—è –∫ –Ω–∞–¥–µ–∂–Ω–æ–π –∏ –ø—Ä–æ—Å—Ç–æ–π –ª–æ–≥–∏–∫–µ –ø–æ–∏—Å–∫–∞ ---
def find_laws_by_keywords(question, max_results=5):
    results = []
    question_lower = question.lower()
    question_words = set(re.findall(r'\b\w{3,}\b', question_lower))

    if not LAW_DB:
        print("‚ö†Ô∏è –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –∑–∞–∫–æ–Ω–æ–≤ –ø—É—Å—Ç–∞!")
        return []

    # –†–∞—Å—à–∏—Ä—è–µ–º –ø–æ–∏—Å–∫–æ–≤—ã–µ —Ç–µ—Ä–º–∏–Ω—ã —Å–∏–Ω–æ–Ω–∏–º–∞–º–∏
    expanded_terms = set(question_words)
    for word in question_words:
        for key_term, synonyms in LEGAL_SYNONYMS.items():
            # –ï—Å–ª–∏ —Å–ª–æ–≤–æ –∏–∑ –≤–æ–ø—Ä–æ—Å–∞ —Å–æ–≤–ø–∞–¥–∞–µ—Ç —Å —Å–∏–Ω–æ–Ω–∏–º–æ–º –∏–ª–∏ –∫–ª—é—á–æ–º, –¥–æ–±–∞–≤–ª—è–µ–º –≤—Å—é –≥—Ä—É–ø–ø—É
            if word in synonyms or word == key_term:
                expanded_terms.update(synonyms)
                expanded_terms.add(key_term)
    
    print(f"üîé –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ —Ç–µ—Ä–º–∏–Ω—ã –ø–æ–∏—Å–∫–∞: {expanded_terms}")

    for entry in LAW_DB:
        title_lower = entry.get("title", "").lower()
        text_lower = entry.get("text", "").lower()
        
        relevance = calculate_relevance(expanded_terms, title_lower, text_lower)

        if relevance > 0:
            entry_copy = entry.copy()
            entry_copy["relevance"] = relevance
            results.append(entry_copy)
            
    results.sort(key=lambda x: x["relevance"], reverse=True)
    return results[:max_results]


# --- –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ü–æ–ª–Ω–æ—Å—Ç—å—é –ø–µ—Ä–µ—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π, –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π —Ä–∞—Å—á–µ—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ ---
def calculate_relevance(expanded_terms, title_lower, text_lower):
    relevance = 0
    
    # 1. –°–æ–≤–ø–∞–¥–µ–Ω–∏–µ –≤ –∑–∞–≥–æ–ª–æ–≤–∫–µ (—Å–∞–º—ã–π –≤—ã—Å–æ–∫–∏–π –≤–µ—Å)
    for term in expanded_terms:
        if term in title_lower:
            relevance += 10 # –î–∞–µ–º –±–æ–ª—å—à–µ –æ—á–∫–æ–≤ –∑–∞ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –≤ –∑–∞–≥–æ–ª–æ–≤–∫–µ
            
    # 2. –°–æ–≤–ø–∞–¥–µ–Ω–∏–µ –≤ —Ç–µ–∫—Å—Ç–µ
    for term in expanded_terms:
        if term in text_lower:
            relevance += 2

    # 3. –ë–æ–Ω—É—Å –∑–∞ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ–≤–ø–∞–≤—à–∏—Ö —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤
    matched_terms_count = sum(1 for term in expanded_terms if term in title_lower or term in text_lower)
    if matched_terms_count > 1:
        relevance += matched_terms_count * 2 # –ë–æ–Ω—É—Å –∑–∞ –∫–∞–∂–¥–æ–µ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ

    return relevance

# --- –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—Ä–æ—Å—Ç—É—é –∏ –Ω–∞–¥–µ–∂–Ω—É—é –∑–∞–≥—Ä—É–∑–∫—É –∏ –æ–±—Ä–∞–±–æ—Ç–∫—É ---
def load_law_db():
    global LAW_DB
    try:
        with open("laws/kazakh_laws.json", "r", encoding="utf-8") as f:
            raw_db = json.load(f)
        # –ü—Ä–æ—Å—Ç–æ —Ä–∞–∑–¥–µ–ª—è–µ–º –∫–æ–¥–µ–∫—Å—ã –Ω–∞ —Å—Ç–∞—Ç—å–∏. –ë–µ–∑ —Å–ª–æ–∂–Ω–æ–π –∏ –Ω–µ–≤–µ—Ä–Ω–æ–π –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏.
        LAW_DB = preprocess_laws_into_articles(raw_db)
        print(f"‚úÖ –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –∑–∞–≥—Ä—É–∂–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ! –ù–∞–π–¥–µ–Ω–æ —Å—Ç–∞—Ç–µ–π: {len(LAW_DB)}")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –±–∞–∑—ã –∑–∞–∫–æ–Ω–æ–≤: {e}")
        LAW_DB = []

def preprocess_laws_into_articles(raw_db):
    # –≠—Ç–∞ —Ñ—É–Ω–∫—Ü–∏—è —Ç–µ–ø–µ—Ä—å –æ—Å–Ω–æ–≤–Ω–∞—è –¥–ª—è –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –¥–∞–Ω–Ω—ã—Ö
    records = []
    heading_pattern = re.compile(r'^(—Å—Ç–∞—Ç—å—è|–≥–ª–∞–≤–∞|—Ä–∞–∑–¥–µ–ª|–ø–æ–¥—Ä–∞–∑–¥–µ–ª|–ø–∞—Ä–∞–≥—Ä–∞—Ñ)', re.IGNORECASE)

    for code_entry in raw_db:
        code_name = code_entry.get("title", "–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è")
        full_text = code_entry.get("text", "")
        source = code_entry.get("source") or determine_source_by_content(code_name)
        items = full_text.splitlines()
        current_title = None
        buffer = []

        for line in items:
            line = line.strip()
            if not line:
                continue
            
            if heading_pattern.match(line):
                if current_title and buffer:
                    records.append({
                        "title": f"{code_name}: {current_title}",
                        "text": " ".join(buffer).strip(),
                        "source": source,
                    })
                buffer = []
                current_title = line
            else:
                buffer.append(line)

        if current_title and buffer:
            records.append({
                "title": f"{code_name}: {current_title}",
                "text": " ".join(buffer).strip(),
                "source": source,
            })
    return records

load_law_db()

# –û—Å—Ç–∞–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ (format_laws, PROMPT_TEMPLATE –∏ –¥—Ä.) –æ—Å—Ç–∞—é—Ç—Å—è —Ç–∞–∫–∏–º–∏ –∂–µ, –∫–∞–∫ –≤ –≤–∞—à–µ–º –ø–æ—Å–ª–µ–¥–Ω–µ–º –∫–æ–¥–µ.
# –Ø –∏—Ö –æ—Å—Ç–∞–≤–ª—è—é –¥–ª—è –ø–æ–ª–Ω–æ—Ç—ã —Ñ–∞–π–ª–∞.

# ... (–≤—Å—Ç–∞–≤—å—Ç–µ —Å—é–¥–∞ –≤–∞—à–∏ —Ñ—É–Ω–∫—Ü–∏–∏ `format_laws`, `determine_source_by_content`, `extract_article_info`, `determine_code_name`)...
# –Ø —Å–∫–æ–ø–∏—Ä—É—é –∏—Ö –∏–∑ –≤–∞—à–µ–≥–æ –∫–æ–¥–∞ –¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞
# üìÑ –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Å—Ç–∞—Ç—å–∏ —Å –ø–æ–¥—Ä–æ–±–Ω—ã–º–∏ –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º–∏ (–≤–∞—à –∫–æ–¥ —Å tooltip)
def format_laws(laws):
    if not laws:
        return "<br><div style='background: #fff3cd; padding: 15px; border-radius: 8px; margin: 10px 0; border-left: 4px solid #ffc107;'>‚ö†Ô∏è <strong>–ü–æ –≤–∞—à–µ–º—É –∑–∞–ø—Ä–æ—Å—É –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö —Å—Ç–∞—Ç–µ–π –Ω–µ –Ω–∞–π–¥–µ–Ω–æ.</strong><br><small style='color: #856404;'>–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –≤–æ–ø—Ä–æ—Å –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –¥—Ä—É–≥–∏–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞.</small></div>"

    output = "<br><div style='background: #e8f4fd; padding: 20px; border-radius: 10px; margin: 15px 0; border-left: 4px solid #0066cc;'>"
    output += "<h3 style='color: #0066cc; margin-top: 0;'>üìö –†–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —Å—Ç–∞—Ç—å–∏ –∑–∞–∫–æ–Ω–æ–¥–∞—Ç–µ–ª—å—Å—Ç–≤–∞ –†–ö</h3>"

    for i, law in enumerate(laws, 1):
        title = law.get('title', '–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è')
        text = law.get('text', '–¢–µ–∫—Å—Ç –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω')
        source = law.get('source', 'https://adilet.zan.kz')
        relevance = law.get('relevance', 0)
        article_info = extract_article_info(title)
        code_name = determine_code_name(title + " " + text)
        preview = text[:400] + "..." if len(text) > 400 else text

        output += f"<div style='background: white; margin: 15px 0; padding: 15px; border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.1);'>"
        output += f"<div style='display: flex; justify-content: space-between; align-items: flex-start; margin-bottom: 10px;'>"
        output += f"<h4 style='color: #0066cc; margin: 0; flex: 1;'>{i}. {title}</h4>"
        output += f"</div>"
        
        if article_info:
            output += f"<div style='background: #f8f9fa; padding: 8px; border-radius: 4px; margin: 8px 0;'><strong style='color: #495057;'>üìç {article_info}</strong></div>"
        
        output += f"<div style='background: #fafbfc; padding: 10px; border-left: 3px solid #dee2e6; margin: 10px 0;'><p style='margin: 0; color: #555; line-height: 1.5;'>{preview}</p></div>"
        
        output += f"<div style='display: flex; justify-content: space-between; align-items: center; margin-top: 12px;'>"
        output += f"<span style='color: #6c757d; font-size: 13px;'><strong>–ò—Å—Ç–æ—á–Ω–∏–∫:</strong> {code_name}</span>"
        
        tooltip_html_text = "–≠—Ç–æ '–æ—á–∫–∏ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏', –∞ –Ω–µ –ø—Ä–æ—Ü–µ–Ω—Ç—ã. –ß–µ–º –≤—ã—à–µ –∑–Ω–∞—á–µ–Ω–∏–µ, —Ç–µ–º –±–æ–ª—å—à–µ —Å—Ç–∞—Ç—å—è —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –≤–∞—à–µ–º—É –∑–∞–ø—Ä–æ—Å—É. –û—á–∫–∏ –Ω–∞—á–∏—Å–ª—è—é—Ç—Å—è –∑–∞ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –≤ –∑–∞–≥–æ–ª–æ–≤–∫–µ –∏ —Ç–µ–∫—Å—Ç–µ —Å—Ç–∞—Ç—å–∏."
        relevance_display = f"""
        <div class="tooltip-container">
            <span style='background: #28a745; color: white; padding: 2px 8px; border-radius: 12px; font-size: 11px; white-space: nowrap;'>
                üìä –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: {relevance}
            </span>
            <span class="tooltip-text">{tooltip_html_text}</span>
        </div>
        """
        
        output += f"<div style='display: flex; align-items: center; gap: 15px;'>"
        output += relevance_display
        output += f"<a href='{source}' target='_blank' style='background: #007bff; color: white; padding: 6px 12px; border-radius: 4px; text-decoration: none; font-size: 12px; font-weight: 500;'>üîó –ß–∏—Ç–∞—Ç—å –ø–æ–ª–Ω–æ—Å—Ç—å—é</a>"
        output += f"</div>"
        
        output += f"</div></div>"

    output += "</div>"
    return output

def extract_article_info(title):
    # ... (–∫–æ–¥ —ç—Ç–æ–π —Ñ—É–Ω–∫—Ü–∏–∏ –Ω–µ –º–µ–Ω—è–µ—Ç—Å—è)
    patterns = [
        r'—Å—Ç–∞—Ç—å—è\s*(\d+)', r'—Å—Ç\.\s*(\d+)', r'–≥–ª–∞–≤–∞\s*(\d+)', r'–≥–ª\.\s*(\d+)',
        r'–ø–∞—Ä–∞–≥—Ä–∞—Ñ\s*(\d+)', r'–ø—É–Ω–∫—Ç\s*(\d+)', r'–ø\.\s*(\d+)',
        r'—Ä–∞–∑–¥–µ–ª\s*([IVX]+|\d+)', r'–ø–æ–¥—Ä–∞–∑–¥–µ–ª\s*(\d+)'
    ]
    found_parts = []
    title_lower = title.lower()
    for pattern in patterns:
        matches = re.findall(pattern, title_lower, re.IGNORECASE)
        for match in matches:
            if '—Å—Ç–∞—Ç—å—è' in pattern or '—Å—Ç.' in pattern: found_parts.append(f"–°—Ç–∞—Ç—å—è {match}")
            elif '–≥–ª–∞–≤–∞' in pattern or '–≥–ª.' in pattern: found_parts.append(f"–ì–ª–∞–≤–∞ {match}")
            elif '–ø–∞—Ä–∞–≥—Ä–∞—Ñ' in pattern: found_parts.append(f"–ü–∞—Ä–∞–≥—Ä–∞—Ñ {match}")
            elif '–ø—É–Ω–∫—Ç' in pattern or '–ø.' in pattern: found_parts.append(f"–ü—É–Ω–∫—Ç {match}")
            elif '—Ä–∞–∑–¥–µ–ª' in pattern: found_parts.append(f"–†–∞–∑–¥–µ–ª {match}")
            elif '–ø–æ–¥—Ä–∞–∑–¥–µ–ª' in pattern: found_parts.append(f"–ü–æ–¥—Ä–∞–∑–¥–µ–ª {match}")
    return ", ".join(found_parts) if found_parts else None


def determine_code_name(content):
    # ... (–∫–æ–¥ —ç—Ç–æ–π —Ñ—É–Ω–∫—Ü–∏–∏ –Ω–µ –º–µ–Ω—è–µ—Ç—Å—è)
    content_lower = content.lower()
    code_mapping = {
        '—É–≥–æ–ª–æ–≤–Ω': '–£–≥–æ–ª–æ–≤–Ω—ã–π –∫–æ–¥–µ–∫—Å –†–ö',
        '–∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç': '–ö–æ–¥–µ–∫—Å –æ–± –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–∏–≤–Ω—ã—Ö –ø—Ä–∞–≤–æ–Ω–∞—Ä—É—à–µ–Ω–∏—è—Ö –†–ö',
        '—Å–æ—Ü–∏–∞–ª—å–Ω': '–°–æ—Ü–∏–∞–ª—å–Ω—ã–π –∫–æ–¥–µ–∫—Å –†–ö',
        '—ç–∫–æ–ª–æ–≥–∏—á': '–≠–∫–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π –∫–æ–¥–µ–∫—Å –†–ö',
        '–≥—Ä–∞–∂–¥–∞–Ω—Å–∫': '–ì—Ä–∞–∂–¥–∞–Ω—Å–∫–∏–π –∫–æ–¥–µ–∫—Å –†–ö',
        '–≤–æ–¥–Ω': '–í–æ–¥–Ω—ã–π –∫–æ–¥–µ–∫—Å –†–ö',
        '–ø—Ä–æ—Ü–µ—Å—Å—É–∞–ª—å–Ω': '–ì—Ä–∞–∂–¥–∞–Ω—Å–∫–∏–π –ø—Ä–æ—Ü–µ—Å—Å—É–∞–ª—å–Ω—ã–π –∫–æ–¥–µ–∫—Å –†–ö',
        '–ø—Ä–µ–¥–ø—Ä–∏–Ω–∏–º–∞—Ç–µ–ª—å—Å–∫': '–ü—Ä–µ–¥–ø—Ä–∏–Ω–∏–º–∞—Ç–µ–ª—å—Å–∫–∏–π –∫–æ–¥–µ–∫—Å –†–ö',
        '–±—é–¥–∂–µ—Ç–Ω': '–ë—é–¥–∂–µ—Ç–Ω—ã–π –∫–æ–¥–µ–∫—Å –†–ö',
        '—Ç—Ä—É–¥–æ–≤': '–¢—Ä—É–¥–æ–≤–æ–π –∫–æ–¥–µ–∫—Å –†–ö',
        '—Å–µ–º–µ–π–Ω': '–°–µ–º–µ–π–Ω—ã–π –∫–æ–¥–µ–∫—Å –†–ö',
        '–Ω–∞–ª–æ–≥–æ–≤': '–ù–∞–ª–æ–≥–æ–≤—ã–π –∫–æ–¥–µ–∫—Å –†–ö',
        '–∑–µ–º–µ–ª—å–Ω': '–ó–µ–º–µ–ª—å–Ω—ã–π –∫–æ–¥–µ–∫—Å –†–ö'
    }
    for keyword, name in code_mapping.items():
        if keyword in content_lower:
            return name
    return "–ó–∞–∫–æ–Ω–æ–¥–∞—Ç–µ–ª—å—Å—Ç–≤–æ –†–ö"

def determine_source_by_content(content):
    # ... (–∫–æ–¥ —ç—Ç–æ–π —Ñ—É–Ω–∫—Ü–∏–∏ –Ω–µ –º–µ–Ω—è–µ—Ç—Å—è)
    content_lower = content.lower()
    source_mapping = {
        '—É–≥–æ–ª–æ–≤–Ω—ã–π –∫–æ–¥–µ–∫—Å': 'https://adilet.zan.kz/rus/docs/K1400000226',
        '—É–≥–æ–ª–æ–≤–Ω': 'https://adilet.zan.kz/rus/docs/K1400000226',
        '–∫–æ–¥–µ–∫—Å –æ–± –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–∏–≤–Ω—ã—Ö –ø—Ä–∞–≤–æ–Ω–∞—Ä—É—à–µ–Ω–∏—è—Ö': 'https://adilet.zan.kz/rus/docs/K1400000235',
        '–∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç': 'https://adilet.zan.kz/rus/docs/K1400000235',
        #... –∏ —Ç–∞–∫ –¥–∞–ª–µ–µ
    }
    for keyword, url in source_mapping.items():
        if keyword in content_lower:
            return url
    return "https://adilet.zan.kz"


PROMPT_TEMPLATE = """
–¢—ã –∫–∞–∑–∞—Ö—Å—Ç–∞–Ω—Å–∫–∏–π —é—Ä–∏—Å—Ç... 
# ... (–≤–∞—à –ø—Ä–æ–º–ø—Ç –Ω–µ –º–µ–Ω—è–µ—Ç—Å—è)
"""

def convert_markdown_to_html(text):
    # ... (–∫–æ–¥ —ç—Ç–æ–π —Ñ—É–Ω–∫—Ü–∏–∏ –Ω–µ –º–µ–Ω—è–µ—Ç—Å—è)
    text = re.sub(r'\*\*(.*?)\*\*', r'<strong>\1</strong>', text)
    text = re.sub(r'\*(.*?)\*', r'<em>\1</em>', text)
    text = re.sub(r'`(.*?)`', r'<code>\1</code>', text)
    text = re.sub(r'^‚Ä¢ ', '<span class="bullet">üî∏</span> ', text, flags=re.MULTILINE)
    text = re.sub(r'^\* ', '<span class="bullet">üî∏</span> ', text, flags=re.MULTILINE)
    text = re.sub(r'^- ', '<span class="bullet">üî∏</span> ', text, flags=re.MULTILINE)
    text = re.sub(r'^(\d+)\. ', r'<strong class="number">\1.</strong> ', text, flags=re.MULTILINE)
    lines = text.split('\n')
    formatted = []
    for line in lines:
        if '<span class="bullet">' in line or '<strong class="number">' in line:
            formatted.append(f'<div class="list-item">{line}</div>')
        else:
            formatted.append(line)
    return '\n'.join(formatted)

# --- –£–õ–£–ß–®–ï–ù–ò–ï: –ù–æ–≤—ã–π —ç–Ω–¥–ø–æ–∏–Ω—Ç /ask –¥–ª—è –ø–æ—Ç–æ–∫–æ–≤–æ–π –ø–µ—Ä–µ–¥–∞—á–∏ ---
@app.route("/ask", methods=["POST"])
def ask_streaming():
    data = request.json
    question = data.get("question", "").strip()
    if not question:
        return jsonify({"error": "–ü—É—Å—Ç–æ–π –≤–æ–ø—Ä–æ—Å"}), 400

    def generate_response():
        try:
            # –°–Ω–∞—á–∞–ª–∞ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç –æ—Ç –ò–ò –∏ –æ—Ç–¥–∞–µ–º –µ–≥–æ –ø–æ —á–∞—Å—Ç—è–º (—Å—Ç—Ä–∏–º–∏–Ω–≥)
            prompt = PROMPT_TEMPLATE.format(question=question)
            stream = model.generate_content(prompt, stream=True)
            for chunk in stream:
                if chunk.text:
                    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –∫–∞–∂–¥—É—é —á–∞—Å—Ç—å –≤ HTML –∏ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –∫–ª–∏–µ–Ω—Ç—É
                    html_chunk = convert_markdown_to_html(chunk.text)
                    yield html_chunk

            # –ü–æ—Å–ª–µ –æ—Ç–≤–µ—Ç–∞ –ò–ò, –∏—â–µ–º –∑–∞–∫–æ–Ω—ã
            laws_found = find_laws_by_keywords(question)
            # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –Ω–∞–π–¥–µ–Ω–Ω—ã–µ –∑–∞–∫–æ–Ω—ã –≤ –æ–¥–∏–Ω HTML –±–ª–æ–∫
            law_section_html = format_laws(laws_found)
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —ç—Ç–æ—Ç –±–ª–æ–∫ –∫–∞–∫ –ø–æ—Å–ª–µ–¥–Ω—é—é —á–∞—Å—Ç—å
            yield law_section_html

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –≤–æ –≤—Ä–µ–º—è —Å—Ç—Ä–∏–º–∏–Ω–≥–∞: {e}")
            yield "<div style='color: red;'>–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞.</div>"

    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ø–æ—Ç–æ–∫–æ–≤—ã–π –æ—Ç–≤–µ—Ç
    return Response(stream_with_context(generate_response()), mimetype='text/html')

# –°—Ç–∞—Ç–∏—á–µ—Å–∫–∏–µ –º–∞—Ä—à—Ä—É—Ç—ã
@app.route("/")
def index():
    return send_from_directory(app.static_folder, "index.html")

@app.route("/<path:path>")
def static_files(path):
    return send_from_directory(app.static_folder, path)

if __name__ == '__main__':
    port = int(os.environ.get('PORT', 8080))
    app.run(host='0.0.0.0', port=port)
